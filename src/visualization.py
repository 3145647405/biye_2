"""
è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–æ¨¡å—
æä¾›å®æ—¶è®­ç»ƒæŒ‡æ ‡ç›‘æ§ã€æ•£ç‚¹å›¾ç»˜åˆ¶å’Œæ›²çº¿æ‹ŸåˆåŠŸèƒ½
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.animation import FuncAnimation
import seaborn as sns
from scipy import stats
from scipy.optimize import curve_fit
import pandas as pd
from typing import Dict, List, Tuple, Any, Optional
import threading
import time
import json
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“ - æ”¹è¿›çš„å­—ä½“è®¾ç½®
def setup_chinese_fonts():
    """è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œæä¾›å¤šç§å›é€€é€‰é¡¹"""
    import matplotlib.font_manager as fm

    # å°è¯•å¤šç§ä¸­æ–‡å­—ä½“
    chinese_fonts = [
        'SimHei',           # Windows é»‘ä½“
        'Microsoft YaHei',  # Windows å¾®è½¯é›…é»‘
        'PingFang SC',      # macOS è‹¹æ–¹
        'Hiragino Sans GB', # macOS å†¬é’é»‘ä½“
        'WenQuanYi Micro Hei', # Linux æ–‡æ³‰é©¿å¾®ç±³é»‘
        'Noto Sans CJK SC', # Google Notoå­—ä½“
        'DejaVu Sans'       # æœ€åå›é€€åˆ°è‹±æ–‡å­—ä½“
    ]

    # è·å–ç³»ç»Ÿå¯ç”¨å­—ä½“
    available_fonts = [f.name for f in fm.fontManager.ttflist]

    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¯ç”¨çš„ä¸­æ–‡å­—ä½“
    selected_font = 'DejaVu Sans'  # é»˜è®¤å›é€€
    for font in chinese_fonts:
        if font in available_fonts:
            selected_font = font
            break

    print(f"é€‰æ‹©å­—ä½“: {selected_font}")

    # è®¾ç½®matplotlibå­—ä½“
    plt.rcParams['font.sans-serif'] = [selected_font, 'DejaVu Sans', 'Arial']
    plt.rcParams['axes.unicode_minus'] = False

    return selected_font

# åˆå§‹åŒ–å­—ä½“è®¾ç½®
setup_chinese_fonts()

# è®¾ç½®seabornæ ·å¼
sns.set_style("whitegrid")
sns.set_palette("husl")


class TrainingVisualizer:
    """è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å™¨"""
    
    def __init__(self, config: Dict[str, Any], save_dir: str = "plots"):
        self.config = config
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        # æ•°æ®å­˜å‚¨
        self.episode_data = {
            'episodes': [],
            'rewards': [],
            'actor_losses': [],
            'critic_losses': [],
            'entropies': [],
            'completion_rates': [],
            'load_utilizations': [],
            'path_lengths': [],
            'collision_counts': [],
            'episode_lengths': [],
            'timestamps': []
        }
        
        # æ­¥çº§æ•°æ®å­˜å‚¨
        self.step_data = {
            'steps': [],
            'actor_losses': [],
            'critic_losses': [],
            'entropies': [],
            'learning_rates': [],
            'timestamps': []
        }
        
        # å¯è§†åŒ–è®¾ç½® - æŒ‰ç”¨æˆ·è¦æ±‚æ¯100ä¸ªepisodeæ›´æ–°ä¸€æ¬¡
        viz_config = config.get('visualization', {})
        self.update_interval = viz_config.get('plot_update_frequency', 100)
        self.enable_realtime = viz_config.get('enable_realtime_plots', True)
        self.save_plots = viz_config.get('save_plots', True)

        # å•ä¸€PNGæ–‡ä»¶è®¾ç½®
        self.single_plot_file = self.save_dir / "training_visualization.png"

        # Losså¹³æ»‘å¤„ç†
        self.loss_smoothing_factor = 0.9  # æŒ‡æ•°ç§»åŠ¨å¹³å‡ç³»æ•°
        self.smoothed_actor_loss = None
        self.smoothed_critic_loss = None
        
        # å›¾å½¢å¯¹è±¡
        self.fig = None
        self.axes = None
        self.is_running = False
        self.update_thread = None
        
        # æ›²çº¿æ‹Ÿåˆå‡½æ•°
        self.fit_functions = {
            'linear': lambda x, a, b: a * x + b,
            'exponential': lambda x, a, b, c: a * np.exp(b * x) + c,
            'polynomial': lambda x, a, b, c, d: a * x**3 + b * x**2 + c * x + d,
            'moving_average': self._moving_average
        }
    
    def add_episode_data(self, episode: int, reward: float, actor_loss: float,
                        critic_loss: float, entropy: float, completion_rate: float,
                        load_utilization: float = 0.0, path_length: float = 0.0,
                        collision_count: int = 0, episode_length: int = 0):
        """æ·»åŠ å›åˆæ•°æ®ï¼ŒåŒ…å«losså¹³æ»‘å¤„ç†"""

        # Losså¹³æ»‘å¤„ç† - ä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡
        if self.smoothed_actor_loss is None:
            self.smoothed_actor_loss = actor_loss
            self.smoothed_critic_loss = critic_loss
        else:
            self.smoothed_actor_loss = (self.loss_smoothing_factor * self.smoothed_actor_loss +
                                      (1 - self.loss_smoothing_factor) * actor_loss)
            self.smoothed_critic_loss = (self.loss_smoothing_factor * self.smoothed_critic_loss +
                                       (1 - self.loss_smoothing_factor) * critic_loss)

        self.episode_data['episodes'].append(episode)
        self.episode_data['rewards'].append(reward)
        self.episode_data['actor_losses'].append(self.smoothed_actor_loss)  # ä½¿ç”¨å¹³æ»‘åçš„loss
        self.episode_data['critic_losses'].append(self.smoothed_critic_loss)  # ä½¿ç”¨å¹³æ»‘åçš„loss
        self.episode_data['entropies'].append(entropy)
        self.episode_data['completion_rates'].append(completion_rate)
        self.episode_data['load_utilizations'].append(load_utilization)
        self.episode_data['path_lengths'].append(path_length)
        self.episode_data['collision_counts'].append(collision_count)
        self.episode_data['episode_lengths'].append(episode_length)
        self.episode_data['timestamps'].append(time.time())
    
    def add_step_data(self, step: int, actor_loss: float, critic_loss: float, 
                     entropy: float, learning_rate: float = 0.0):
        """æ·»åŠ æ­¥çº§æ•°æ®"""
        self.step_data['steps'].append(step)
        self.step_data['actor_losses'].append(actor_loss)
        self.step_data['critic_losses'].append(critic_loss)
        self.step_data['entropies'].append(entropy)
        self.step_data['learning_rates'].append(learning_rate)
        self.step_data['timestamps'].append(time.time())
    
    def _moving_average(self, data: np.ndarray, window: int = 50) -> np.ndarray:
        """è®¡ç®—ç§»åŠ¨å¹³å‡"""
        if len(data) < window:
            return data
        
        result = np.zeros_like(data)
        for i in range(len(data)):
            start_idx = max(0, i - window + 1)
            result[i] = np.mean(data[start_idx:i+1])
        
        return result
    
    def fit_curve(self, x_data: np.ndarray, y_data: np.ndarray, 
                  method: str = 'moving_average') -> Tuple[np.ndarray, Dict[str, Any]]:
        """æ‹Ÿåˆæ›²çº¿"""
        if len(x_data) < 10:  # æ•°æ®ç‚¹å¤ªå°‘ï¼Œè¿”å›åŸæ•°æ®
            return y_data, {'method': method, 'params': None}
        
        try:
            if method == 'moving_average':
                fitted_y = self._moving_average(y_data, window=min(50, len(y_data)//4))
                return fitted_y, {'method': method, 'window': min(50, len(y_data)//4)}
            
            elif method == 'linear':
                popt, _ = curve_fit(self.fit_functions['linear'], x_data, y_data)
                fitted_y = self.fit_functions['linear'](x_data, *popt)
                return fitted_y, {'method': method, 'params': popt.tolist()}
            
            elif method == 'polynomial':
                # ä½¿ç”¨numpyçš„å¤šé¡¹å¼æ‹Ÿåˆ
                coeffs = np.polyfit(x_data, y_data, deg=min(3, len(x_data)//10))
                fitted_y = np.polyval(coeffs, x_data)
                return fitted_y, {'method': method, 'params': coeffs.tolist()}
            
            elif method == 'exponential':
                # æŒ‡æ•°æ‹Ÿåˆéœ€è¦ç‰¹æ®Šå¤„ç†
                try:
                    popt, _ = curve_fit(self.fit_functions['exponential'], x_data, y_data, 
                                      maxfev=1000)
                    fitted_y = self.fit_functions['exponential'](x_data, *popt)
                    return fitted_y, {'method': method, 'params': popt.tolist()}
                except:
                    # å¦‚æœæŒ‡æ•°æ‹Ÿåˆå¤±è´¥ï¼Œå›é€€åˆ°ç§»åŠ¨å¹³å‡
                    fitted_y = self._moving_average(y_data)
                    return fitted_y, {'method': 'moving_average_fallback', 'params': None}
            
        except Exception as e:
            print(f"æ›²çº¿æ‹Ÿåˆå¤±è´¥ ({method}): {e}")
            # å›é€€åˆ°ç§»åŠ¨å¹³å‡
            fitted_y = self._moving_average(y_data)
            return fitted_y, {'method': 'moving_average_fallback', 'params': None}
        
        return y_data, {'method': 'none', 'params': None}
    
    def create_training_plots(self, save_path: Optional[str] = None) -> plt.Figure:
        """åˆ›å»ºè®­ç»ƒè¿‡ç¨‹å›¾è¡¨ - ä¼˜åŒ–å¤§æ•°æ®é‡æ˜¾ç¤º"""
        # åˆ›å»ºå­å›¾ - è°ƒæ•´å¸ƒå±€å’Œå¤§å°ä»¥é€‚åº”å¤§æ•°æ®é‡
        fig, axes = plt.subplots(3, 3, figsize=(24, 18))
        fig.suptitle('Multi-AGV MAPPO-Attention Training Visualization (12K Episodes)',
                    fontsize=18, fontweight='bold', y=0.98)

        # æ£€æŸ¥æ•°æ®æ˜¯å¦è¶³å¤Ÿ
        if len(self.episode_data['episodes']) < 2:
            for ax in axes.flat:
                ax.text(0.5, 0.5, 'Insufficient Data\nNeed More Training Episodes',
                       ha='center', va='center', transform=ax.transAxes, fontsize=12)
            return fig

        episodes = np.array(self.episode_data['episodes'])
        print(f"ç»˜åˆ¶å›¾è¡¨: {len(episodes)} ä¸ªå›åˆçš„æ•°æ®")

        # 1. å›åˆå¥–åŠ±æ•£ç‚¹å›¾å’Œæ‹Ÿåˆæ›²çº¿ - ä¼˜åŒ–æ•£ç‚¹æ ·å¼
        ax = axes[0, 0]
        rewards = np.array(self.episode_data['rewards'])

        # ä¼˜åŒ–æ•£ç‚¹å›¾æ ·å¼ - æ‰©å¤§æ•£ç‚¹åŠå¾„ä¸€å€ï¼Œçº¿å®½åŠ ç²—0.5å€
        point_size = max(4, min(8, 200 / len(rewards) * 15)) * 2  # æ•£ç‚¹åŠå¾„æ‰©å¤§ä¸€å€
        inner_alpha = max(0.6, min(0.9, 800 / len(rewards)))  # å†…éƒ¨é€æ˜åº¦
        edge_alpha = max(0.2, min(0.5, 400 / len(rewards)))   # è¾¹ç¼˜é€æ˜åº¦

        # ä½¿ç”¨ä¸åŒé¢œè‰² - æ·±è“è‰²æ•£ç‚¹
        ax.scatter(episodes, rewards, alpha=inner_alpha, s=point_size, c='#2E4A7A',
                  label='Episode Rewards', edgecolors='#1A2B42', linewidths=0.45,
                  rasterized=True)
        print(f"å¥–åŠ±æ•£ç‚¹å›¾: {len(rewards)} ä¸ªæ•°æ®ç‚¹ (ç‚¹å¤§å°: {point_size:.1f}, å†…éƒ¨é€æ˜åº¦: {inner_alpha:.2f})")

        # æ‹Ÿåˆæ›²çº¿ - ä½¿ç”¨ä¸æ•£ç‚¹ä¸åŒçš„é¢œè‰²
        if len(rewards) > 5:  # é™ä½é˜ˆå€¼ç¡®ä¿èƒ½æ˜¾ç¤ºæ‹Ÿåˆæ›²çº¿
            try:
                fitted_rewards, _ = self.fit_curve(episodes, rewards, 'moving_average')
                ax.plot(episodes, fitted_rewards, '#FF6B35', linewidth=2.5, label='Moving Average', alpha=0.9)
                print(f"ç§»åŠ¨å¹³å‡æ‹Ÿåˆå®Œæˆ")

                # æ·»åŠ çº¿æ€§è¶‹åŠ¿çº¿
                if len(rewards) > 10:
                    linear_fit, _ = self.fit_curve(episodes, rewards, 'linear')
                    ax.plot(episodes, linear_fit, '#4CAF50', linestyle='--', linewidth=2, alpha=0.8, label='Linear Trend')
                    print(f"çº¿æ€§è¶‹åŠ¿æ‹Ÿåˆå®Œæˆ")
            except Exception as e:
                print(f"æ‹Ÿåˆæ›²çº¿ç”Ÿæˆå¤±è´¥: {e}")

        ax.set_xlabel('Episode Number', fontsize=11)
        ax.set_ylabel('Episode Reward', fontsize=11)
        ax.set_title('Episode Reward Progress', fontsize=12, fontweight='bold')
        ax.legend(loc='best', fontsize=10)
        ax.grid(True, alpha=0.3)

        # 2. ActoræŸå¤±æ•£ç‚¹å›¾ - ä¼˜åŒ–æ ·å¼
        ax = axes[0, 1]
        actor_losses = np.array(self.episode_data['actor_losses'])
        ax.scatter(episodes, actor_losses, alpha=inner_alpha, s=point_size, color='#D84315',
                  label='Actor Loss', edgecolors='#BF360C', linewidths=0.45, rasterized=True)

        if len(actor_losses) > 5:
            try:
                fitted_losses, _ = self.fit_curve(episodes, actor_losses, 'moving_average')
                ax.plot(episodes, fitted_losses, '#FF9800', linewidth=2.5, label='Moving Average', alpha=0.9)
            except Exception as e:
                print(f"ActoræŸå¤±æ‹Ÿåˆå¤±è´¥: {e}")

        ax.set_xlabel('Episode Number', fontsize=11)
        ax.set_ylabel('Actor Loss', fontsize=11)
        ax.set_title('Actor Network Loss', fontsize=12, fontweight='bold')
        ax.legend(loc='best', fontsize=10)
        ax.grid(True, alpha=0.3)

        # 3. CriticæŸå¤±æ•£ç‚¹å›¾ - ä¼˜åŒ–æ ·å¼
        ax = axes[0, 2]
        critic_losses = np.array(self.episode_data['critic_losses'])
        ax.scatter(episodes, critic_losses, alpha=inner_alpha, s=point_size, color='#2E7D32',
                  label='Critic Loss', edgecolors='#1B5E20', linewidths=0.45, rasterized=True)

        if len(critic_losses) > 5:
            try:
                fitted_losses, _ = self.fit_curve(episodes, critic_losses, 'moving_average')
                ax.plot(episodes, fitted_losses, '#8BC34A', linewidth=2.5, label='Moving Average', alpha=0.9)
            except Exception as e:
                print(f"CriticæŸå¤±æ‹Ÿåˆå¤±è´¥: {e}")

        ax.set_xlabel('Episode Number', fontsize=11)
        ax.set_ylabel('Critic Loss', fontsize=11)
        ax.set_title('Critic Network Loss', fontsize=12, fontweight='bold')
        ax.legend(loc='best', fontsize=10)
        ax.grid(True, alpha=0.3)

        # 4. ç†µå€¼æ•£ç‚¹å›¾ - ä¼˜åŒ–æ ·å¼
        ax = axes[1, 0]
        entropies = np.array(self.episode_data['entropies'])
        ax.scatter(episodes, entropies, alpha=inner_alpha, s=point_size, color='#7B1FA2',
                  label='Policy Entropy', edgecolors='#4A148C', linewidths=0.45, rasterized=True)

        if len(entropies) > 5:
            try:
                fitted_entropies, _ = self.fit_curve(episodes, entropies, 'moving_average')
                ax.plot(episodes, fitted_entropies, '#E91E63', linewidth=2.5, label='Moving Average', alpha=0.9)
            except Exception as e:
                print(f"ç†µå€¼æ‹Ÿåˆå¤±è´¥: {e}")

        ax.set_xlabel('Episode Number', fontsize=11)
        ax.set_ylabel('Policy Entropy', fontsize=11)
        ax.set_title('Policy Entropy Change', fontsize=12, fontweight='bold')
        ax.legend(loc='best', fontsize=10)
        ax.grid(True, alpha=0.3)

        # 5. ä»»åŠ¡å®Œæˆç‡ - ä¼˜åŒ–æ ·å¼
        ax = axes[1, 1]
        completion_rates = np.array(self.episode_data['completion_rates'])
        ax.scatter(episodes, completion_rates, alpha=inner_alpha, s=point_size, color='#1565C0',
                  label='Completion Rate', edgecolors='#0D47A1', linewidths=0.45, rasterized=True)

        if len(completion_rates) > 5:
            try:
                fitted_rates, _ = self.fit_curve(episodes, completion_rates, 'moving_average')
                ax.plot(episodes, fitted_rates, '#03A9F4', linewidth=2.5, label='Moving Average', alpha=0.9)
            except Exception as e:
                print(f"å®Œæˆç‡æ‹Ÿåˆå¤±è´¥: {e}")

        ax.set_xlabel('Episode Number', fontsize=11)
        ax.set_ylabel('Task Completion Rate', fontsize=11)
        ax.set_title('Task Completion Rate Progress', fontsize=12, fontweight='bold')
        ax.set_ylim(0, 1)
        ax.legend(loc='best', fontsize=10)
        ax.grid(True, alpha=0.3)

        # 6. AGVè½½é‡åˆ©ç”¨ç‡ - ä¼˜åŒ–æ ·å¼
        ax = axes[1, 2]
        load_utils = np.array(self.episode_data['load_utilizations'])
        if len(load_utils) > 0 and np.any(load_utils > 0):
            ax.scatter(episodes, load_utils, alpha=inner_alpha, s=point_size, color='#00838F',
                      label='Load Utilization', edgecolors='#004D40', linewidths=0.45, rasterized=True)

            if len(load_utils) > 5:
                try:
                    fitted_utils, _ = self.fit_curve(episodes, load_utils, 'moving_average')
                    ax.plot(episodes, fitted_utils, '#26C6DA', linewidth=2.5, label='Moving Average', alpha=0.9)
                except Exception as e:
                    print(f"è½½é‡åˆ©ç”¨ç‡æ‹Ÿåˆå¤±è´¥: {e}")
        else:
            ax.text(0.5, 0.5, 'Load Utilization Data\nNot Yet Collected',
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)

        ax.set_xlabel('Episode Number', fontsize=11)
        ax.set_ylabel('Load Utilization Rate', fontsize=11)
        ax.set_title('AGV Load Utilization', fontsize=12, fontweight='bold')
        ax.legend(loc='best', fontsize=10)
        ax.grid(True, alpha=0.3)

        # 7. è·¯å¾„é•¿åº¦ - ä¼˜åŒ–æ ·å¼
        ax = axes[2, 0]
        path_lengths = np.array(self.episode_data['path_lengths'])
        if len(path_lengths) > 0 and np.any(path_lengths > 0):
            ax.scatter(episodes, path_lengths, alpha=inner_alpha, s=point_size, color='#5D4037',
                      label='Avg Path Length', edgecolors='#3E2723', linewidths=0.45, rasterized=True)

            if len(path_lengths) > 5:
                try:
                    fitted_paths, _ = self.fit_curve(episodes, path_lengths, 'moving_average')
                    ax.plot(episodes, fitted_paths, '#8D6E63', linewidth=2.5, label='Moving Average', alpha=0.9)
                except Exception as e:
                    print(f"è·¯å¾„é•¿åº¦æ‹Ÿåˆå¤±è´¥: {e}")
        else:
            ax.text(0.5, 0.5, 'Path Length Data\nNot Yet Collected',
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)

        ax.set_xlabel('Episode Number', fontsize=11)
        ax.set_ylabel('Average Path Length', fontsize=11)
        ax.set_title('AGV Average Path Length', fontsize=12, fontweight='bold')
        ax.legend(loc='best', fontsize=10)
        ax.grid(True, alpha=0.3)

        # 8. ç¢°æ’æ¬¡æ•° - ä¼˜åŒ–æ ·å¼
        ax = axes[2, 1]
        collisions = np.array(self.episode_data['collision_counts'])
        ax.scatter(episodes, collisions, alpha=inner_alpha, s=point_size, color='#C62828',
                  label='Collision Count', edgecolors='#B71C1C', linewidths=0.45, rasterized=True)

        if len(collisions) > 5:
            try:
                fitted_collisions, _ = self.fit_curve(episodes, collisions, 'moving_average')
                ax.plot(episodes, fitted_collisions, '#F44336', linewidth=2.5, label='Moving Average', alpha=0.9)
            except Exception as e:
                print(f"ç¢°æ’æ¬¡æ•°æ‹Ÿåˆå¤±è´¥: {e}")

        ax.set_xlabel('Episode Number', fontsize=11)
        ax.set_ylabel('Collision Count', fontsize=11)
        ax.set_title('Collisions per Episode', fontsize=12, fontweight='bold')
        ax.legend(loc='best', fontsize=10)
        ax.grid(True, alpha=0.3)

        # 9. ç»¼åˆæ€§èƒ½æŒ‡æ ‡ - ä¼˜åŒ–æ ·å¼
        ax = axes[2, 2]
        if len(completion_rates) > 0 and len(collisions) > 0:
            # è®¡ç®—ç»¼åˆæ€§èƒ½åˆ†æ•° (å®Œæˆç‡é«˜ï¼Œç¢°æ’å°‘)
            max_collisions = max(collisions) if max(collisions) > 0 else 1
            normalized_collisions = collisions / max_collisions
            performance_score = completion_rates - 0.3 * normalized_collisions

            ax.scatter(episodes, performance_score, alpha=inner_alpha, s=point_size, color='#F57C00',
                      label='Performance Score', edgecolors='#E65100', linewidths=0.45, rasterized=True)

            if len(performance_score) > 5:
                try:
                    fitted_perf, _ = self.fit_curve(episodes, performance_score, 'moving_average')
                    ax.plot(episodes, fitted_perf, '#FFC107', linewidth=2.5, label='Moving Average', alpha=0.9)
                except Exception as e:
                    print(f"ç»¼åˆæ€§èƒ½æ‹Ÿåˆå¤±è´¥: {e}")
        else:
            ax.text(0.5, 0.5, 'Performance Data\nCalculating...',
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)

        ax.set_xlabel('Episode Number', fontsize=11)
        ax.set_ylabel('Performance Score', fontsize=11)
        ax.set_title('Overall Performance Assessment', fontsize=12, fontweight='bold')
        ax.legend(loc='best', fontsize=10)
        ax.grid(True, alpha=0.3)

        # ä¼˜åŒ–å¸ƒå±€ - é€‚åº”å¤§æ•°æ®é‡æ˜¾ç¤º
        plt.tight_layout(pad=2.0, h_pad=2.5, w_pad=2.0)
        
        # ä¿å­˜å›¾è¡¨ - åªä¿å­˜ä¸€å¼ PNGå›¾ç‰‡
        if save_path:
            save_file = save_path
        else:
            save_file = self.single_plot_file

        plt.savefig(save_file, dpi=300, bbox_inches='tight')
        print(f"è®­ç»ƒå›¾è¡¨å·²ä¿å­˜åˆ°: {save_file}")
        
        return fig

    def start_realtime_visualization(self, update_frequency: int = 10):
        """å¯åŠ¨å®æ—¶å¯è§†åŒ– - æ¯10ä¸ªepisodeæ›´æ–°ä¸€æ¬¡"""
        if self.enable_realtime and not self.is_running:
            self.is_running = True
            self.update_frequency = update_frequency
            self.update_thread = threading.Thread(target=self._realtime_update_loop, daemon=True)
            self.update_thread.start()
            print(f"å®æ—¶å¯è§†åŒ–å·²å¯åŠ¨ - æ¯{update_frequency}ä¸ªepisodeæ›´æ–°ä¸€æ¬¡")

    def stop_realtime_visualization(self):
        """åœæ­¢å®æ—¶å¯è§†åŒ–"""
        self.is_running = False
        if self.update_thread:
            self.update_thread.join(timeout=2)
        print("å®æ—¶å¯è§†åŒ–å·²åœæ­¢")

    def _realtime_update_loop(self):
        """å®æ—¶æ›´æ–°å¾ªç¯ - ä¿®å¤æ»åé—®é¢˜"""
        last_update_episode = 0

        while self.is_running:
            try:
                current_episodes = len(self.episode_data['episodes'])

                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–° - æ¯100ä¸ªepisodeæ›´æ–°ä¸€æ¬¡ï¼Œä¸è®­ç»ƒåŒæ­¥
                episodes_since_last_update = current_episodes - last_update_episode

                if episodes_since_last_update >= self.update_frequency and current_episodes >= self.update_frequency:
                    # åˆ›å»ºå¹¶ä¿å­˜å›¾è¡¨åˆ°å›ºå®šæ–‡ä»¶
                    fig = self.create_training_plots()

                    # å…³é—­å›¾å½¢ä»¥é‡Šæ”¾å†…å­˜
                    plt.close(fig)

                    last_update_episode = current_episodes
                    print(f"ğŸ“Š è®­ç»ƒå›¾è¡¨å·²æ›´æ–° (å›åˆ: {current_episodes}, è·ä¸Šæ¬¡æ›´æ–°: {episodes_since_last_update}) - ä¿å­˜åˆ°: {self.single_plot_file}")

                # å‡å°‘ç­‰å¾…æ—¶é—´ï¼Œæé«˜å“åº”é€Ÿåº¦
                time.sleep(1)

            except Exception as e:
                print(f"å®æ—¶å¯è§†åŒ–æ›´æ–°é”™è¯¯: {e}")
                time.sleep(5)

    def save_data_to_json(self, filepath: str):
        """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
        data = {
            'episode_data': self.episode_data,
            'step_data': self.step_data,
            'config': self.config,
            'save_time': time.time()
        }

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

    def load_data_from_json(self, filepath: str):
        """ä»JSONæ–‡ä»¶åŠ è½½æ•°æ®"""
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)

        self.episode_data = data.get('episode_data', self.episode_data)
        self.step_data = data.get('step_data', self.step_data)

        print(f"å·²åŠ è½½ {len(self.episode_data['episodes'])} ä¸ªå›åˆçš„æ•°æ®")

    def create_summary_report(self, save_path: str):
        """åˆ›å»ºè®­ç»ƒæ€»ç»“æŠ¥å‘Š"""
        if len(self.episode_data['episodes']) < 5:
            print("æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆæ€»ç»“æŠ¥å‘Š")
            return

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        episodes = np.array(self.episode_data['episodes'])
        rewards = np.array(self.episode_data['rewards'])
        completion_rates = np.array(self.episode_data['completion_rates'])

        # åˆ›å»ºæŠ¥å‘Š
        report = {
            'training_summary': {
                'total_episodes': len(episodes),
                'training_duration': self.episode_data['timestamps'][-1] - self.episode_data['timestamps'][0],
                'final_performance': {
                    'avg_reward_last_100': np.mean(rewards[-100:]) if len(rewards) >= 100 else np.mean(rewards),
                    'avg_completion_rate_last_100': np.mean(completion_rates[-100:]) if len(completion_rates) >= 100 else np.mean(completion_rates),
                    'best_reward': np.max(rewards),
                    'best_completion_rate': np.max(completion_rates)
                },
                'learning_progress': {
                    'reward_improvement': rewards[-1] - rewards[0] if len(rewards) > 1 else 0,
                    'completion_rate_improvement': completion_rates[-1] - completion_rates[0] if len(completion_rates) > 1 else 0
                }
            },
            'detailed_metrics': {
                'rewards': {
                    'mean': float(np.mean(rewards)),
                    'std': float(np.std(rewards)),
                    'min': float(np.min(rewards)),
                    'max': float(np.max(rewards))
                },
                'completion_rates': {
                    'mean': float(np.mean(completion_rates)),
                    'std': float(np.std(completion_rates)),
                    'min': float(np.min(completion_rates)),
                    'max': float(np.max(completion_rates))
                }
            }
        }

        # ä¿å­˜æŠ¥å‘Š
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"è®­ç»ƒæ€»ç»“æŠ¥å‘Šå·²ä¿å­˜åˆ°: {save_path}")
        return report


class EnhancedMetricsCollector:
    """å¢å¼ºçš„æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.episode_metrics = []
        self.step_metrics = []

    def collect_episode_metrics(self, env, episode: int, episode_reward: float,
                              episode_length: int, info: Dict[str, Any]) -> Dict[str, float]:
        """æ”¶é›†å›åˆçº§æŒ‡æ ‡"""
        # åŸºç¡€æŒ‡æ ‡
        metrics = {
            'episode': episode,
            'episode_reward': episode_reward,
            'episode_length': episode_length,
            'completion_rate': info.get('completion_rate', 0.0)
        }

        # AGVæ€§èƒ½æŒ‡æ ‡
        agv_states = info.get('agv_states', [])
        if agv_states:
            # è®¡ç®—è½½é‡åˆ©ç”¨ç‡
            total_load = sum(state[2] for state in agv_states)  # state[2] æ˜¯å½“å‰è½½é‡
            max_total_load = len(agv_states) * env.max_load
            load_utilization = total_load / max_total_load if max_total_load > 0 else 0
            metrics['load_utilization'] = load_utilization

            # è®¡ç®—å¹³å‡è·¯å¾„é•¿åº¦ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
            avg_path_length = episode_length / len(agv_states) if len(agv_states) > 0 else 0
            metrics['path_length'] = avg_path_length
        else:
            metrics['load_utilization'] = 0.0
            metrics['path_length'] = 0.0

        # ç¯å¢ƒç»Ÿè®¡æŒ‡æ ‡
        episode_stats = info.get('episode_stats', {})
        metrics['collision_count'] = episode_stats.get('collisions', 0)
        metrics['deadlock_count'] = episode_stats.get('deadlocks', 0)

        # æ•ˆç‡æŒ‡æ ‡
        if metrics['completion_rate'] > 0:
            metrics['efficiency_score'] = metrics['completion_rate'] / (metrics['episode_length'] / 100)
        else:
            metrics['efficiency_score'] = 0.0

        self.episode_metrics.append(metrics)
        return metrics

    def collect_step_metrics(self, step: int, actor_loss: float, critic_loss: float,
                           entropy: float, learning_rate: float = 0.0) -> Dict[str, float]:
        """æ”¶é›†æ­¥çº§æŒ‡æ ‡"""
        metrics = {
            'step': step,
            'actor_loss': actor_loss,
            'critic_loss': critic_loss,
            'entropy': entropy,
            'learning_rate': learning_rate,
            'timestamp': time.time()
        }

        self.step_metrics.append(metrics)
        return metrics

    def get_recent_metrics(self, window: int = 100) -> Dict[str, float]:
        """è·å–æœ€è¿‘çš„å¹³å‡æŒ‡æ ‡"""
        if len(self.episode_metrics) < window:
            recent_episodes = self.episode_metrics
        else:
            recent_episodes = self.episode_metrics[-window:]

        if not recent_episodes:
            return {}

        # è®¡ç®—å¹³å‡å€¼
        avg_metrics = {}
        for key in recent_episodes[0].keys():
            if key != 'episode':
                values = [ep[key] for ep in recent_episodes if key in ep]
                avg_metrics[f'avg_{key}'] = np.mean(values) if values else 0.0

        return avg_metrics
