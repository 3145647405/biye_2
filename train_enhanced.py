#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆå¤šAGVè°ƒåº¦MAPPO-Attentionè®­ç»ƒè„šæœ¬
æ”¯æŒåŠ¨æ€å¯è§†åŒ–ã€æ—¶é—´æˆ³æ–‡ä»¶å¤¹å’Œå®Œæ•´çš„æŒ‡æ ‡æ”¶é›†
"""

import os
import sys
import argparse
import torch
import numpy as np
from pathlib import Path
from torch.utils.tensorboard import SummaryWriter
import time
import shutil
from datetime import datetime
from typing import Dict, Any

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.environment import AGVEnv
from src.trainer import MAPPOTrainer
from src.utils import load_config, setup_logging, set_seed, create_directories
from src.visualization import TrainingVisualizer, EnhancedMetricsCollector
import matplotlib.pyplot as plt


def create_timestamped_results_dir(config: Dict[str, Any], script_name: str) -> Path:
    """åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„ç»“æœç›®å½•"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_root = Path(config['training']['results_dir'])
    results_dir = results_root / f"{script_name}_{timestamp}"
    
    # åˆ›å»ºç›®å½•ç»“æ„
    results_dir.mkdir(parents=True, exist_ok=True)
    (results_dir / "checkpoints").mkdir(exist_ok=True)
    (results_dir / "logs").mkdir(exist_ok=True)
    (results_dir / "plots").mkdir(exist_ok=True)
    (results_dir / "data").mkdir(exist_ok=True)
    
    # å¤åˆ¶é…ç½®æ–‡ä»¶
    if config['training'].get('save_config_copy', True):
        shutil.copy2('config.yaml', results_dir / 'config.yaml')
    
    return results_dir


class CurriculumLearning:
    """è¯¾ç¨‹å­¦ä¹ ç®¡ç†å™¨"""
    
    def __init__(self, config, logger):
        self.config = config
        self.logger = logger
        self.curriculum_config = config.get('curriculum', {})
        self.enable = self.curriculum_config.get('enable', False)
        self.stages = self.curriculum_config.get('stages', [])
        self.current_stage = 0
        
        if self.enable:
            self.logger.info(f"è¯¾ç¨‹å­¦ä¹ å·²å¯ç”¨ï¼Œå…± {len(self.stages)} ä¸ªé˜¶æ®µ")
            for i, stage in enumerate(self.stages):
                self.logger.info(f"  é˜¶æ®µ{i+1}: {stage['name']} - {stage['num_agvs']}ä¸ªAGV, {stage['num_tasks']}ä¸ªä»»åŠ¡")
        else:
            self.logger.info("è¯¾ç¨‹å­¦ä¹ å·²ç¦ç”¨")
    
    def get_current_stage_config(self):
        """è·å–å½“å‰é˜¶æ®µçš„é…ç½®"""
        if not self.enable or self.current_stage >= len(self.stages):
            return self.config
        
        # å¤åˆ¶åŸºç¡€é…ç½®
        stage_config = self.config.copy()
        current_stage = self.stages[self.current_stage]
        
        # æ›´æ–°ç¯å¢ƒé…ç½®
        for key, value in current_stage.items():
            if key not in ['until', 'name']:
                if key in stage_config['environment']:
                    stage_config['environment'][key] = value
        
        self.logger.info(f"å½“å‰é˜¶æ®µ: {current_stage.get('name', f'stage_{self.current_stage}')}")
        self.logger.info(f"  ç¯å¢ƒé…ç½®: {current_stage['num_agvs']}ä¸ªAGV, {current_stage['num_tasks']}ä¸ªä»»åŠ¡, åœ°å›¾{current_stage.get('map_width', 26)}x{current_stage.get('map_height', 10)}")
        return stage_config
    
    def should_advance(self, metrics):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µ"""
        if not self.enable or self.current_stage >= len(self.stages):
            return False
        
        current_stage = self.stages[self.current_stage]
        until_conditions = current_stage.get('until', {})
        
        # æ£€æŸ¥æ‰€æœ‰æ¡ä»¶
        for condition, threshold in until_conditions.items():
            if condition == 'min_episodes':
                continue  # è¿™ä¸ªåœ¨å¤–éƒ¨æ£€æŸ¥
            
            metric_value = metrics.get(condition.replace('min_', ''), 0)
            if metric_value < threshold:
                self.logger.info(f"é˜¶æ®µæ™‹çº§æ¡ä»¶æœªæ»¡è¶³: {condition} = {metric_value:.3f} < {threshold}")
                return False
        
        self.logger.info("æ‰€æœ‰é˜¶æ®µæ™‹çº§æ¡ä»¶å·²æ»¡è¶³")
        return True
    
    def advance_stage(self):
        """è¿›å…¥ä¸‹ä¸€é˜¶æ®µ"""
        if self.current_stage < len(self.stages) - 1:
            self.current_stage += 1
            stage_name = self.stages[self.current_stage].get('name', f'stage_{self.current_stage}')
            self.logger.info(f"ğŸ‰ è¿›å…¥ä¸‹ä¸€é˜¶æ®µ: {stage_name}")
            return True
        return False
    
    def is_completed(self):
        """æ£€æŸ¥è¯¾ç¨‹å­¦ä¹ æ˜¯å¦å®Œæˆ"""
        return self.current_stage >= len(self.stages) - 1


def train_stage(trainer, stage_config, curriculum, writer, visualizer, metrics_collector, 
                results_dir, stage_episodes=0):
    """è®­ç»ƒå•ä¸ªé˜¶æ®µ"""
    logger = trainer.logger
    train_config = stage_config['training']
    
    # é˜¶æ®µå‚æ•°
    buffer_size = train_config['buffer_size']
    eval_frequency = train_config['eval_frequency']
    save_frequency = train_config['save_frequency']
    
    # å½“å‰é˜¶æ®µçš„æœ€å°å›åˆæ•°
    if curriculum.enable and curriculum.current_stage < len(curriculum.stages):
        current_stage = curriculum.stages[curriculum.current_stage]
        min_episodes = current_stage.get('until', {}).get('min_episodes', 1000)
        stage_name = current_stage.get('name', f'stage_{curriculum.current_stage}')
    else:
        min_episodes = 0
        stage_name = "final_stage"
    
    logger.info(f"ğŸš€ å¼€å§‹è®­ç»ƒé˜¶æ®µ: {stage_name}")
    logger.info(f"   æœ€å°å›åˆæ•°: {min_episodes}")
    logger.info(f"   ç¯å¢ƒé…ç½®: {stage_config['environment']['num_agvs']}ä¸ªAGV, {stage_config['environment']['num_tasks']}ä¸ªä»»åŠ¡")
    
    step_count = 0
    last_eval_step = 0
    last_save_step = 0
    last_plot_update = 0
    
    # å¯è§†åŒ–é…ç½®
    plot_update_freq = stage_config.get('visualization', {}).get('plot_update_frequency', 20)
    
    while True:
        # æ”¶é›†ç»éªŒ
        start_time = time.time()
        rollout_metrics = trainer.collect_rollouts(buffer_size)
        collect_time = time.time() - start_time
        
        # æ›´æ–°ç½‘ç»œ
        start_time = time.time()
        update_metrics = trainer.update()
        update_time = time.time() - start_time
        
        step_count += buffer_size
        stage_episodes += rollout_metrics['episodes_completed']
        
        # æ”¶é›†è¯¦ç»†æŒ‡æ ‡
        if rollout_metrics['episodes_completed'] > 0:
            # è·å–æœ€æ–°çš„ç¯å¢ƒä¿¡æ¯
            env_info = trainer.env._get_info()
            
            # æ”¶é›†å›åˆæŒ‡æ ‡
            episode_metrics = metrics_collector.collect_episode_metrics(
                trainer.env, 
                trainer.episode_count,
                rollout_metrics['avg_episode_reward'],
                rollout_metrics['avg_episode_length'],
                env_info
            )
            
            # æ·»åŠ åˆ°å¯è§†åŒ–å™¨
            visualizer.add_episode_data(
                episode=trainer.episode_count,
                reward=rollout_metrics['avg_episode_reward'],
                actor_loss=update_metrics['actor_loss'],
                critic_loss=update_metrics['critic_loss'],
                entropy=update_metrics['entropy'],
                completion_rate=rollout_metrics['avg_completion_rate'],
                load_utilization=episode_metrics.get('load_utilization', 0.0),
                path_length=episode_metrics.get('path_length', 0.0),
                collision_count=episode_metrics.get('collision_count', 0),
                episode_length=rollout_metrics['avg_episode_length']
            )
        
        # æ”¶é›†æ­¥çº§æŒ‡æ ‡
        step_metrics = metrics_collector.collect_step_metrics(
            trainer.total_steps,
            update_metrics['actor_loss'],
            update_metrics['critic_loss'],
            update_metrics['entropy'],
            train_config['learning_rate']
        )
        
        # è®°å½•æŒ‡æ ‡
        all_metrics = {**rollout_metrics, **update_metrics}
        all_metrics.update({
            'collect_time': collect_time,
            'update_time': update_time,
            'stage_episodes': stage_episodes,
            'current_stage': curriculum.current_stage,
            'stage_name': stage_name
        })
        
        # TensorBoardè®°å½•
        for key, value in all_metrics.items():
            if isinstance(value, (int, float)):  # åªè®°å½•æ•°å€¼ç±»å‹
                writer.add_scalar(f'train/{key}', value, trainer.total_steps)
        
        # æ›´æ–°å¯è§†åŒ–å›¾è¡¨
        if (trainer.episode_count - last_plot_update >= plot_update_freq and 
            trainer.episode_count > 5):
            try:
                # åˆ›å»ºå¹¶ä¿å­˜æœ€æ–°çš„è®­ç»ƒå›¾è¡¨
                fig = visualizer.create_training_plots()
                plot_path = results_dir / "plots" / "training_progress_live.png"
                fig.savefig(plot_path, dpi=300, bbox_inches='tight')
                plt.close(fig)
                
                # ä¿å­˜æ•°æ®
                data_path = results_dir / "data" / "training_data.json"
                visualizer.save_data_to_json(str(data_path))
                
                last_plot_update = trainer.episode_count
                logger.info(f"ğŸ“Š è®­ç»ƒå›¾è¡¨å·²æ›´æ–° (å›åˆ: {trainer.episode_count})")
                
            except Exception as e:
                logger.warning(f"å¯è§†åŒ–æ›´æ–°å¤±è´¥: {e}")
        
        # æ—¥å¿—è¾“å‡º
        if step_count % 1000 == 0:
            logger.info(
                f"ğŸ“ˆ æ­¥æ•°: {trainer.total_steps:,}, å›åˆ: {trainer.episode_count:,}, "
                f"å¹³å‡å¥–åŠ±: {rollout_metrics['avg_episode_reward']:.2f}, "
                f"å®Œæˆç‡: {rollout_metrics['avg_completion_rate']:.2f}, "
                f"ActoræŸå¤±: {update_metrics['actor_loss']:.4f}, "
                f"é˜¶æ®µè¿›åº¦: {stage_episodes}/{min_episodes}"
            )
        
        # è¯„ä¼°
        if trainer.total_steps - last_eval_step >= eval_frequency:
            eval_metrics = trainer.evaluate(train_config['eval_episodes'])
            
            for key, value in eval_metrics.items():
                writer.add_scalar(f'eval/{key}', value, trainer.total_steps)
            
            logger.info(
                f"ğŸ¯ è¯„ä¼°ç»“æœ - å¹³å‡å¥–åŠ±: {eval_metrics['eval_mean_reward']:.2f}, "
                f"å®Œæˆç‡: {eval_metrics['eval_mean_completion_rate']:.2f}"
            )
            
            last_eval_step = trainer.total_steps
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if trainer.total_steps - last_save_step >= save_frequency:
            checkpoint_path = results_dir / "checkpoints" / f"checkpoint_{trainer.total_steps}.pt"
            trainer.save_checkpoint(str(checkpoint_path))
            last_save_step = trainer.total_steps
        
        # æ£€æŸ¥è¯¾ç¨‹å­¦ä¹ è¿›åº¦
        if curriculum.enable:
            # æ£€æŸ¥æœ€å°å›åˆæ•°
            if stage_episodes >= min_episodes:
                # æ£€æŸ¥å…¶ä»–æ¡ä»¶
                recent_metrics = metrics_collector.get_recent_metrics(100)
                
                if curriculum.should_advance(recent_metrics):
                    logger.info(f"âœ… é˜¶æ®µ {stage_name} å®Œæˆï¼Œå·²è®­ç»ƒ {stage_episodes} å›åˆ")
                    
                    # ä¿å­˜é˜¶æ®µæ€»ç»“
                    stage_summary_path = results_dir / f"stage_{curriculum.current_stage}_summary.json"
                    visualizer.create_summary_report(str(stage_summary_path))
                    
                    return stage_episodes
        
        # æ£€æŸ¥æ€»è®­ç»ƒæ­¥æ•°é™åˆ¶
        if trainer.total_steps >= train_config['total_timesteps']:
            logger.info("â° è¾¾åˆ°æœ€å¤§è®­ç»ƒæ­¥æ•°ï¼Œè®­ç»ƒç»“æŸ")
            return stage_episodes


def main():
    parser = argparse.ArgumentParser(description='å¢å¼ºç‰ˆå¤šAGVè°ƒåº¦MAPPO-Attentionè®­ç»ƒ')
    parser.add_argument('--config', type=str, default='config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--resume', type=str, default=None, help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    parser.add_argument('--device', type=str, default='auto', help='è®¾å¤‡é€‰æ‹© (cpu/cuda/auto)')
    parser.add_argument('--render', action='store_true', help='å¯ç”¨ç¯å¢ƒæ¸²æŸ“')
    parser.add_argument('--no-visualization', action='store_true', help='ç¦ç”¨å®æ—¶å¯è§†åŒ–')

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    config = load_config(args.config)

    # è®¾ç½®è®¾å¤‡
    if args.device == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(args.device)

    print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")

    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)

    # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„ç»“æœç›®å½•
    script_name = "mappo_attention_training"
    results_dir = create_timestamped_results_dir(config, script_name)
    print(f"ğŸ“ ç»“æœå°†ä¿å­˜åˆ°: {results_dir}")

    # æ›´æ–°é…ç½®ä¸­çš„è·¯å¾„
    config['training']['checkpoint_dir'] = str(results_dir / "checkpoints")
    config['training']['log_dir'] = str(results_dir / "logs")

    # åˆ›å»ºç›®å½•
    create_directories(config)

    # è®¾ç½®æ—¥å¿—
    logger = setup_logging("MAPPO-AGV")
    logger.info("ğŸ¯ å¼€å§‹å¢å¼ºç‰ˆå¤šAGVè°ƒåº¦MAPPO-Attentionè®­ç»ƒ")
    logger.info(f"ğŸ“‹ é…ç½®æ–‡ä»¶: {args.config}")
    logger.info(f"ğŸ’» è®¾å¤‡: {device}")
    logger.info(f"ğŸ² éšæœºç§å­: {args.seed}")
    logger.info(f"ğŸ“‚ ç»“æœç›®å½•: {results_dir}")

    # åˆå§‹åŒ–è¯¾ç¨‹å­¦ä¹ 
    curriculum = CurriculumLearning(config, logger)

    # åˆå§‹åŒ–å¯è§†åŒ–å™¨
    visualizer = TrainingVisualizer(config, save_dir=str(results_dir / "plots"))
    if not args.no_visualization:
        plot_update_freq = config.get('visualization', {}).get('plot_update_frequency', 20)
        visualizer.start_realtime_visualization(plot_update_freq)

    # åˆå§‹åŒ–æŒ‡æ ‡æ”¶é›†å™¨
    metrics_collector = EnhancedMetricsCollector(config)

    # TensorBoard
    writer = SummaryWriter(log_dir=str(results_dir / "logs"))

    # è®­ç»ƒå¾ªç¯
    total_stage_episodes = 0
    training_start_time = time.time()

    try:
        while True:
            # è·å–å½“å‰é˜¶æ®µé…ç½®
            stage_config = curriculum.get_current_stage_config()

            # åˆ›å»ºç¯å¢ƒ
            env = AGVEnv(stage_config)
            if args.render:
                env.render()

            # åˆ›å»ºè®­ç»ƒå™¨
            if 'trainer' not in locals():
                trainer = MAPPOTrainer(stage_config, env, device)

                # æ¢å¤è®­ç»ƒ
                if args.resume:
                    trainer.load_checkpoint(args.resume)
                    logger.info(f"ğŸ“¥ ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {args.resume}")
            else:
                # æ›´æ–°ç¯å¢ƒï¼ˆä¿æŒè®­ç»ƒå™¨çŠ¶æ€ï¼‰
                trainer.env = env
                trainer.buffer.num_agents = stage_config['environment']['num_agvs']

            # è®­ç»ƒå½“å‰é˜¶æ®µ
            stage_episodes = train_stage(
                trainer, stage_config, curriculum, writer,
                visualizer, metrics_collector, results_dir, total_stage_episodes
            )
            total_stage_episodes = stage_episodes

            # æ£€æŸ¥æ˜¯å¦ç»§ç»­ä¸‹ä¸€é˜¶æ®µ
            if curriculum.enable and not curriculum.is_completed():
                if curriculum.advance_stage():
                    continue

            # è®­ç»ƒå®Œæˆ
            break

    except KeyboardInterrupt:
        logger.info("âš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

    finally:
        # åœæ­¢å®æ—¶å¯è§†åŒ–
        if not args.no_visualization:
            visualizer.stop_realtime_visualization()

        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_checkpoint = results_dir / "checkpoints" / "final_model.pt"
        if 'trainer' in locals():
            trainer.save_checkpoint(str(final_checkpoint))
            logger.info(f"ğŸ’¾ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜åˆ°: {final_checkpoint}")

        # ç”Ÿæˆæœ€ç»ˆè®­ç»ƒå›¾è¡¨
        try:
            final_plot = visualizer.create_training_plots()
            final_plot_path = results_dir / "plots" / "final_training_results.png"
            final_plot.savefig(final_plot_path, dpi=300, bbox_inches='tight')
            import matplotlib.pyplot as plt
            plt.close(final_plot)
            logger.info(f"ğŸ“Š æœ€ç»ˆè®­ç»ƒå›¾è¡¨å·²ä¿å­˜åˆ°: {final_plot_path}")
        except Exception as e:
            logger.warning(f"ç”Ÿæˆæœ€ç»ˆå›¾è¡¨å¤±è´¥: {e}")

        # ä¿å­˜æœ€ç»ˆæ•°æ®å’ŒæŠ¥å‘Š
        try:
            final_data_path = results_dir / "data" / "final_training_data.json"
            visualizer.save_data_to_json(str(final_data_path))

            final_report_path = results_dir / "training_summary_report.json"
            visualizer.create_summary_report(str(final_report_path))

            logger.info(f"ğŸ“‹ è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ°: {final_data_path}")
            logger.info(f"ğŸ“„ è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜åˆ°: {final_report_path}")
        except Exception as e:
            logger.warning(f"ä¿å­˜æœ€ç»ˆæ•°æ®å¤±è´¥: {e}")

        # è®¡ç®—æ€»è®­ç»ƒæ—¶é—´
        total_training_time = time.time() - training_start_time
        hours = int(total_training_time // 3600)
        minutes = int((total_training_time % 3600) // 60)
        seconds = int(total_training_time % 60)

        logger.info(f"â±ï¸ æ€»è®­ç»ƒæ—¶é—´: {hours}å°æ—¶ {minutes}åˆ†é’Ÿ {seconds}ç§’")
        logger.info(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {results_dir}")

        # å…³é—­èµ„æº
        writer.close()
        if 'env' in locals():
            env.close()


if __name__ == "__main__":
    main()
