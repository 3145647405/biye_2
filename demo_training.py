#!/usr/bin/env python3
"""
å®Œæ•´è®­ç»ƒæ¼”ç¤ºè„šæœ¬
å±•ç¤ºä¼˜åŒ–åçš„å¯è§†åŒ–ç³»ç»Ÿï¼šå•ä¸€PNGå›¾ç‰‡ï¼Œæ¯100ä¸ªepisodeæ›´æ–°ï¼Œå¹³æ»‘çš„lossæ›²çº¿
"""

import os
import sys
import time
import yaml
import logging
import numpy as np
from datetime import datetime
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append('src')

from visualization import TrainingVisualizer

def demo_complete_training():
    """æ¼”ç¤ºå®Œæ•´çš„è®­ç»ƒè¿‡ç¨‹"""
    
    print("ğŸ¯ å¼€å§‹å®Œæ•´è®­ç»ƒè¿‡ç¨‹æ¼”ç¤º")
    
    # åˆ›å»ºç»“æœç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_dir = Path(f"results/demo_complete_training_{timestamp}")
    result_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ“‚ ç»“æœç›®å½•: {result_dir}")
    
    # åŠ è½½é…ç½®
    with open('config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # åˆå§‹åŒ–å¯è§†åŒ–å™¨ - æ¯100ä¸ªepisodeæ›´æ–°ä¸€æ¬¡
    visualizer = TrainingVisualizer(config, str(result_dir / 'plots'))
    visualizer.start_realtime_visualization(update_frequency=100)
    
    print("ğŸ“Š å¯è§†åŒ–ç³»ç»Ÿå·²å¯åŠ¨ - æ¯100ä¸ªepisodeæ›´æ–°ä¸€æ¬¡ï¼Œåªç”Ÿæˆä¸€å¼ PNGå›¾ç‰‡")
    
    # è¯¾ç¨‹å­¦ä¹ é˜¶æ®µ
    stages = config['curriculum']['stages']
    print(f"ğŸ“ è¯¾ç¨‹å­¦ä¹ å·²å¯ç”¨ï¼Œå…± {len(stages)} ä¸ªé˜¶æ®µ")
    
    total_episodes = 0
    
    try:
        for stage_idx, stage in enumerate(stages, 1):
            stage_name = stage['name']
            num_agvs = stage['num_agvs']
            num_tasks = stage['num_tasks']
            
            print(f"\nğŸš€ å¼€å§‹è®­ç»ƒé˜¶æ®µ {stage_idx}/9: {stage_name}")
            print(f"   é…ç½®: {num_agvs}ä¸ªAGV, {num_tasks}ä¸ªä»»åŠ¡")
            
            # é˜¶æ®µè®­ç»ƒå‚æ•°
            stage_episodes = stage['until']['min_episodes']
            target_completion_rate = stage['until']['min_completion_rate']
            target_return = stage['until']['min_return']
            
            print(f"   ç›®æ ‡: {stage_episodes}å›åˆ, å®Œæˆç‡â‰¥{target_completion_rate}, å¥–åŠ±â‰¥{target_return}")
            
            # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
            for episode in range(stage_episodes):
                total_episodes += 1
                
                # æ¨¡æ‹Ÿå­¦ä¹ è¿›åº¦
                progress = episode / stage_episodes
                
                # æ¨¡æ‹Ÿå¥–åŠ±æ”¹å–„ï¼ˆæ›´å¹³æ»‘çš„æ›²çº¿ï¼‰
                base_reward = target_return - 15
                reward_improvement = 15 * (1 - np.exp(-progress * 3))  # æŒ‡æ•°å¢é•¿
                noise = np.random.normal(0, 1)  # å‡å°‘å™ªå£°
                episode_reward = base_reward + reward_improvement + noise
                
                # æ¨¡æ‹Ÿå®Œæˆç‡æ”¹å–„
                completion_rate = min(target_completion_rate + 0.1, 
                                    progress * (target_completion_rate + 0.2) + np.random.normal(0, 0.02))
                completion_rate = max(0, completion_rate)
                
                # æ¨¡æ‹Ÿå¹³æ»‘çš„lossæ›²çº¿
                actor_loss = 0.8 * np.exp(-progress * 2) + 0.1 + np.random.normal(0, 0.05)
                critic_loss = 0.5 * np.exp(-progress * 1.8) + 0.05 + np.random.normal(0, 0.03)
                entropy = 1.2 * np.exp(-progress * 1.5) + 0.2 + np.random.normal(0, 0.05)
                
                # ç¡®ä¿losså€¼ä¸ºæ­£
                actor_loss = max(0.01, actor_loss)
                critic_loss = max(0.01, critic_loss)
                entropy = max(0.01, entropy)
                
                # æ¨¡æ‹ŸAGVç‰¹å®šæŒ‡æ ‡
                load_utilization = min(0.95, progress * 0.7 + 0.2 + np.random.normal(0, 0.05))
                path_length = max(8, 40 - progress * 15 + np.random.normal(0, 2))
                collision_count = max(0, int(8 * (1 - progress) + np.random.normal(0, 0.5)))
                
                # è®°å½•æ•°æ®åˆ°å¯è§†åŒ–å™¨
                visualizer.add_episode_data(
                    episode=total_episodes,
                    reward=episode_reward,
                    actor_loss=actor_loss,
                    critic_loss=critic_loss,
                    entropy=entropy,
                    completion_rate=completion_rate,
                    load_utilization=load_utilization,
                    path_length=path_length,
                    collision_count=collision_count
                )
                
                # æ¯10ä¸ªå›åˆæ˜¾ç¤ºè¿›åº¦
                if (episode + 1) % 10 == 0:
                    print(f"   é˜¶æ®µ{stage_idx} å›åˆ{episode+1}/{stage_episodes}: "
                          f"å¥–åŠ±={episode_reward:.2f}, å®Œæˆç‡={completion_rate:.2f}, "
                          f"Actor Loss={actor_loss:.3f}, Critic Loss={critic_loss:.3f}")
                
                # æ£€æŸ¥æ™‹çº§æ¡ä»¶
                if (completion_rate >= target_completion_rate and 
                    episode_reward >= target_return and
                    episode >= stage_episodes * 0.6):  # è‡³å°‘å®Œæˆ60%è®­ç»ƒ
                    print(f"âœ… é˜¶æ®µ {stage_idx} æå‰å®Œæˆ! "
                          f"å®Œæˆç‡={completion_rate:.2f}, å¥–åŠ±={episode_reward:.2f}")
                    break
                
                # æ¨¡æ‹Ÿè®­ç»ƒå»¶è¿Ÿ
                time.sleep(0.01)  # å¾ˆçŸ­çš„å»¶è¿Ÿä»¥ä¾¿è§‚å¯Ÿ
            
            print(f"ğŸ‰ é˜¶æ®µ {stage_idx} è®­ç»ƒå®Œæˆ! æ€»å›åˆæ•°: {total_episodes}")
            time.sleep(1)  # é˜¶æ®µé—´çŸ­æš‚ä¼‘æ¯
    
    except KeyboardInterrupt:
        print("\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    finally:
        # åœæ­¢å¯è§†åŒ–
        visualizer.stop_realtime_visualization()
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        final_report = {
            "training_completed": True,
            "total_episodes": total_episodes,
            "total_stages_completed": stage_idx,
            "result_directory": str(result_dir),
            "single_visualization_file": str(visualizer.single_plot_file),
            "improvements": [
                "å•ä¸€PNGå›¾ç‰‡å¯è§†åŒ–",
                "æ¯100ä¸ªepisodeæ›´æ–°ä¸€æ¬¡",
                "å¹³æ»‘çš„Actor/Critic lossæ›²çº¿",
                "å®Œæ•´çš„9é˜¶æ®µè¯¾ç¨‹å­¦ä¹ "
            ]
        }
        
        # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
        import json
        with open(result_dir / 'final_training_report.json', 'w', encoding='utf-8') as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜è®­ç»ƒæ•°æ®
        visualizer.save_data_to_json(result_dir / 'training_data.json')
        
        # ç”Ÿæˆæœ€ç»ˆå¯è§†åŒ–
        visualizer.create_training_plots(result_dir / 'final_training_summary.png')
        
        print("\nğŸ‰ å®Œæ•´è®­ç»ƒè¿‡ç¨‹æ¼”ç¤ºå®Œæˆ!")
        print(f"ğŸ“Š æ€»å›åˆæ•°: {total_episodes}")
        print(f"ğŸ“ˆ å®Œæˆé˜¶æ®µæ•°: {stage_idx}/{len(stages)}")
        print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {result_dir}")
        print(f"ğŸ–¼ï¸  å•ä¸€è®­ç»ƒå¯è§†åŒ–å›¾ç‰‡: {visualizer.single_plot_file}")
        print("\nâœ¨ ä¸»è¦æ”¹è¿›:")
        print("   âœ… åªç”Ÿæˆä¸€å¼ PNGå›¾ç‰‡ï¼Œæ¯100ä¸ªepisodeæ›´æ–°")
        print("   âœ… Actorå’ŒCritic lossæ›²çº¿æ›´åŠ å¹³æ»‘")
        print("   âœ… å®Œæ•´çš„9é˜¶æ®µè¯¾ç¨‹å­¦ä¹ æ¼”ç¤º")
        print("   âœ… å®æ—¶å¯è§†åŒ–ç³»ç»Ÿä¼˜åŒ–")
        
        return result_dir

if __name__ == "__main__":
    demo_complete_training()
