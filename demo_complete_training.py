#!/usr/bin/env python3
"""
å®Œæ•´è®­ç»ƒè¿‡ç¨‹æ¼”ç¤ºè„šæœ¬
å±•ç¤ºä»ç¬¬ä¸€é˜¶æ®µåˆ°æœ€åé˜¶æ®µçš„å®Œæ•´è¯¾ç¨‹å­¦ä¹ è¿‡ç¨‹
"""

import os
import sys
import time
import yaml
import logging
import numpy as np
from datetime import datetime
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append('src')

from environment import MultiAGVEnvironment
from models import MAPPOAgent
from trainer import MAPPOTrainer
from visualization import TrainingVisualizer
from utils import setup_logging, save_config

def demo_complete_training():
    """æ¼”ç¤ºå®Œæ•´çš„è®­ç»ƒè¿‡ç¨‹"""
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging("MAPPO-AGV-DEMO")
    
    # åˆ›å»ºç»“æœç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_dir = Path(f"results/demo_complete_training_{timestamp}")
    result_dir.mkdir(parents=True, exist_ok=True)
    
    logger.info("ğŸ¯ å¼€å§‹å®Œæ•´è®­ç»ƒè¿‡ç¨‹æ¼”ç¤º")
    logger.info(f"ğŸ“‚ ç»“æœç›®å½•: {result_dir}")
    
    # åŠ è½½é…ç½®
    with open('config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # ä¿å­˜é…ç½®å‰¯æœ¬
    save_config(config, result_dir / 'config.yaml')
    
    # åˆå§‹åŒ–å¯è§†åŒ–å™¨
    visualizer = TrainingVisualizer(result_dir / 'plots')
    
    # è¯¾ç¨‹å­¦ä¹ é˜¶æ®µ
    stages = config['curriculum']['stages']
    logger.info(f"è¯¾ç¨‹å­¦ä¹ å·²å¯ç”¨ï¼Œå…± {len(stages)} ä¸ªé˜¶æ®µ")
    
    total_episodes = 0
    
    for stage_idx, stage in enumerate(stages, 1):
        stage_name = stage['name']
        num_agvs = stage['num_agvs']
        num_tasks = stage['num_tasks']
        max_steps = stage['max_steps']
        map_width = stage['map_width']
        map_height = stage['map_height']
        
        logger.info(f"ğŸš€ å¼€å§‹è®­ç»ƒé˜¶æ®µ {stage_idx}/9: {stage_name}")
        logger.info(f"   é…ç½®: {num_agvs}ä¸ªAGV, {num_tasks}ä¸ªä»»åŠ¡, åœ°å›¾{map_width}x{map_height}")
        
        # åˆ›å»ºç¯å¢ƒ
        env = MultiAGVEnvironment(
            num_agvs=num_agvs,
            num_tasks=num_tasks,
            map_width=map_width,
            map_height=map_height,
            max_steps=max_steps
        )
        
        # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
        stage_episodes = stage['until']['min_episodes']
        target_completion_rate = stage['until']['min_completion_rate']
        target_return = stage['until']['min_return']
        
        logger.info(f"   ç›®æ ‡: {stage_episodes}å›åˆ, å®Œæˆç‡â‰¥{target_completion_rate}, å¥–åŠ±â‰¥{target_return}")
        
        # æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
        for episode in range(stage_episodes):
            total_episodes += 1
            
            # æ¨¡æ‹Ÿå­¦ä¹ è¿›åº¦
            progress = episode / stage_episodes
            
            # æ¨¡æ‹Ÿå¥–åŠ±æ”¹å–„
            base_reward = target_return - 20
            reward_improvement = 20 * progress
            episode_reward = base_reward + reward_improvement + np.random.normal(0, 2)
            
            # æ¨¡æ‹Ÿå®Œæˆç‡æ”¹å–„
            completion_rate = min(target_completion_rate + 0.1, progress * (target_completion_rate + 0.2))
            completion_rate = max(0, completion_rate + np.random.normal(0, 0.05))
            
            # æ¨¡æ‹Ÿå…¶ä»–æŒ‡æ ‡
            actor_loss = 0.5 * np.exp(-progress * 2) + np.random.normal(0, 0.1)
            critic_loss = 0.3 * np.exp(-progress * 1.5) + np.random.normal(0, 0.05)
            entropy = 1.0 * np.exp(-progress * 1) + np.random.normal(0, 0.1)
            
            # æ¨¡æ‹ŸAGVç‰¹å®šæŒ‡æ ‡
            load_utilization = min(0.9, progress * 0.8 + np.random.normal(0, 0.1))
            path_length = max(10, 50 - progress * 20 + np.random.normal(0, 3))
            collision_count = max(0, 10 * (1 - progress) + np.random.normal(0, 1))
            
            # è®°å½•æ•°æ®
            visualizer.record_episode(
                episode=total_episodes,
                reward=episode_reward,
                actor_loss=actor_loss,
                critic_loss=critic_loss,
                entropy=entropy,
                completion_rate=completion_rate,
                load_utilization=load_utilization,
                path_length=path_length,
                collision_count=collision_count
            )
            
            # æ¯5ä¸ªå›åˆæ›´æ–°ä¸€æ¬¡å¯è§†åŒ–
            if (episode + 1) % 5 == 0:
                visualizer.update_plots()
                logger.info(f"   å›åˆ {episode+1}/{stage_episodes}: å¥–åŠ±={episode_reward:.2f}, å®Œæˆç‡={completion_rate:.2f}")
        
        # æ£€æŸ¥æ™‹çº§æ¡ä»¶
        current_completion_rate = completion_rate
        current_reward = episode_reward
        
        if current_completion_rate >= target_completion_rate and current_reward >= target_return:
            logger.info(f"âœ… é˜¶æ®µ {stage_idx} å®Œæˆ! å®Œæˆç‡={current_completion_rate:.2f}, å¥–åŠ±={current_reward:.2f}")
        else:
            logger.info(f"âš ï¸  é˜¶æ®µ {stage_idx} æœªå®Œå…¨è¾¾æ ‡ï¼Œä½†ç»§ç»­ä¸‹ä¸€é˜¶æ®µè¿›è¡Œæ¼”ç¤º")
        
        # ä¿å­˜é˜¶æ®µæ£€æŸ¥ç‚¹
        checkpoint_path = result_dir / 'checkpoints' / f'stage_{stage_idx}_checkpoint.pt'
        checkpoint_path.parent.mkdir(exist_ok=True)
        
        # æ¨¡æ‹Ÿä¿å­˜æ£€æŸ¥ç‚¹
        logger.info(f"ğŸ’¾ é˜¶æ®µæ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
        
        time.sleep(1)  # çŸ­æš‚æš‚åœä»¥ä¾¿è§‚å¯Ÿ
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    final_report = {
        "training_completed": True,
        "total_episodes": total_episodes,
        "total_stages": len(stages),
        "final_performance": {
            "reward": float(episode_reward),
            "completion_rate": float(completion_rate),
            "load_utilization": float(load_utilization)
        },
        "training_time": f"{time.time():.2f} seconds (demo)",
        "result_directory": str(result_dir)
    }
    
    # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
    import json
    with open(result_dir / 'final_training_report.json', 'w', encoding='utf-8') as f:
        json.dump(final_report, f, indent=2, ensure_ascii=False)
    
    # ç”Ÿæˆæœ€ç»ˆå¯è§†åŒ–
    visualizer.create_training_plots(result_dir / 'final_training_summary.png')
    
    logger.info("ğŸ‰ å®Œæ•´è®­ç»ƒè¿‡ç¨‹æ¼”ç¤ºå®Œæˆ!")
    logger.info(f"ğŸ“Š æ€»å›åˆæ•°: {total_episodes}")
    logger.info(f"ğŸ“ˆ æœ€ç»ˆæ€§èƒ½: å¥–åŠ±={episode_reward:.2f}, å®Œæˆç‡={completion_rate:.2f}")
    logger.info(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {result_dir}")
    
    return result_dir

if __name__ == "__main__":
    demo_complete_training()
